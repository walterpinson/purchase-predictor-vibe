# Purchase Predictor Architecture

This document details the technical architecture, preprocessing pipeline, and project structure of the Purchase Predictor system.

## Preprocessing Architecture

The project uses a **centralized, configuration-driven preprocessing approach** to ensure consistency and eliminate code duplication:

### Core Components

- **`src/utilities/preprocessing.py`**: Contains the `PurchaseDataPreprocessor` class with configurable methods:
  - `fit_transform_training_data()`: Fits preprocessing pipeline and transforms training data
  - `transform_test_data()`: Applies fitted transformations to test data  
  - `transform_inference_data()`: Transforms new data for real-time predictions
  - `load_fitted_preprocessor()`: Loads saved preprocessing pipeline for inference

### Configuration-Driven Processing

The preprocessor supports flexible configuration via `config.yaml`:

```yaml
data_processing:
  handle_missing: "drop"        # Options: "drop", "impute"
  use_float_types: true         # Use float64 for MLFlow compatibility
  drop_threshold: 0.1           # Drop features with >10% missing values
```

**Key Features:**

- **Missing Data Handling**: Configurable strategy for handling missing values
- **MLFlow Optimization**: Uses float64 types to eliminate MLFlow integer schema warnings
- **Production Robustness**: Handles missing data gracefully at inference time
- **Type Consistency**: Ensures consistent data types across training and inference

### Benefits

- **Consistency**: Identical transformations across training, testing, and inference
- **Maintainability**: Single source of truth for all preprocessing logic
- **Reliability**: Eliminates synchronization issues between duplicate code
- **Scalability**: Easy to add new preprocessing steps in one place
- **Configuration Control**: Easy to modify processing behavior without code changes
- **MLFlow Compatible**: Eliminates common MLFlow warnings and compatibility issues

### Integration

All scripts (`src/pipeline/data_prep.py`, `src/pipeline/train.py`, `src/scripts/score.py`) use the shared preprocessor, ensuring the same feature engineering pipeline throughout the ML lifecycle.

## Detailed Project Structure

```bash
purchase-predictor-vibe/
â”œâ”€â”€ README.md                    # Quick start guide and project overview
â”œâ”€â”€ conda.yaml                   # Environment definition
â”œâ”€â”€ .env.local                   # Environment variables (not in git)
â”œâ”€â”€ .gitignore                   # Git ignore file
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ DEPLOYMENT_GUIDE.md      # Deployment strategies and troubleshooting
â”‚   â”œâ”€â”€ REGIONAL_DEPLOYMENT_GUIDE.md  # Regional deployment configurations
â”‚   â”œâ”€â”€ UNIQUE_NAMING_IMPLEMENTATION.md  # Endpoint naming strategies
â”‚   â”œâ”€â”€ ARCHITECTURE.md          # This file - technical architecture
â”‚   â”œâ”€â”€ CONFIGURATION.md         # Configuration reference
â”‚   â”œâ”€â”€ API_REFERENCE.md         # API documentation
â”‚   â”œâ”€â”€ TROUBLESHOOTING.md       # Troubleshooting guide
â”‚   â””â”€â”€ DATA_SCHEMA.md           # Data schema and model details
â”œâ”€â”€ scripts/                     # Project management scripts
â”‚   â”œâ”€â”€ run_pipeline.sh          # ğŸŒŸ MAIN PIPELINE - Complete workflow
â”‚   â”œâ”€â”€ run_pipeline_aci.sh      # ACI-style deployment pipeline
â”‚   â”œâ”€â”€ run_pipeline_local.sh    # Local development pipeline
â”‚   â”œâ”€â”€ cleanup_endpoint.sh      # Endpoint cleanup utility
â”‚   â”œâ”€â”€ fix_environment.sh       # Environment setup utility
â”‚   â”œâ”€â”€ check_azure_quotas.sh    # Azure quota monitoring script
â”‚   â””â”€â”€ quota_monitor.py         # Python quota monitoring utility
â”œâ”€â”€ config/                      # Configuration and utilities
â”‚   â”œâ”€â”€ config.yaml              # Main configuration settings
â”‚   â”œâ”€â”€ config_loader.py         # Shared configuration loader utility (uses piny)
â”‚   â””â”€â”€ test_config.py           # Configuration validation and testing script
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ pipeline/                # MLOps pipeline scripts
â”‚   â”‚   â”œâ”€â”€ data_prep.py         # Data generation and preprocessing (Step 1)
â”‚   â”‚   â”œâ”€â”€ train.py             # Model training script
â”‚   â”‚   â”œâ”€â”€ register.py          # Model registration script
â”‚   â”‚   â”œâ”€â”€ deploy_managed_endpoint.py  # Primary Azure ML managed endpoint deployment (with archival)
â”‚   â”‚   â”œâ”€â”€ deploy_aci.py               # ACI-style deployment (cost-optimized)
â”‚   â”‚   â”œâ”€â”€ deploy_azure_ml.py          # Azure ML integration verification
â”‚   â”œâ”€â”€ scripts/                 # Deployment scripts
â”‚   â”‚   â””â”€â”€ score.py             # Scoring script for endpoint
â”‚   â””â”€â”€ utilities/               # Shared utilities
â”‚       â”œâ”€â”€ preprocessing.py     # Shared preprocessing utility class
â”‚       â”œâ”€â”€ endpoint_naming.py   # Endpoint naming utilities
â”‚       â”œâ”€â”€ local_inference.py   # Local development server
â”‚       â”œâ”€â”€ server_manager.py    # Deployment archival management
â”‚       â”œâ”€â”€ test_regional_config.py  # Regional deployment testing
â”‚       â””â”€â”€ debug_config.py      # Configuration loading debugging
â”œâ”€â”€ context/                     # Project documentation
â”‚   â”œâ”€â”€ prd.md                   # Product Requirements
â”‚   â”œâ”€â”€ spec.md                  # Technical Specification
â”‚   â””â”€â”€ plan.md                  # Build Plan
â”œâ”€â”€ sample_data/                 # Generated training data
â”‚   â”œâ”€â”€ train.csv
â”‚   â””â”€â”€ test.csv
â”œâ”€â”€ processed_data/              # Preprocessed data
â”œâ”€â”€ server/                      # Deployment artifacts (auto-generated)
â”‚   â”œâ”€â”€ score.py                 # Current deployment scoring script  
â”‚   â”œâ”€â”€ preprocessing.py         # Current deployment preprocessing
â”‚   â”œâ”€â”€ deployment_info.json     # Current deployment metadata
â”‚   â””â”€â”€ archives/                # Timestamped deployment archives
â””â”€â”€ models/                      # Model artifacts
    â”œâ”€â”€ model.pkl
    â”œâ”€â”€ label_encoder.pkl
    â”œâ”€â”€ preprocessing_metadata.pkl
    â”œâ”€â”€ registration_info.yaml
    â””â”€â”€ endpoint_info.yaml
```

## Component Details

### Pipeline Scripts (`src/pipeline/`)

**Data Preparation (`data_prep.py`)**
- Generates synthetic training data with realistic distributions
- Applies configurable preprocessing (missing data handling, type conversion)
- Saves both raw and processed data for transparency
- Uses shared preprocessing utilities for consistency

**Model Training (`train.py`)**
- Trains Random Forest classifier (configurable)
- Uses MLFlow for experiment tracking with explicit schema
- Eliminates MLFlow integer schema warnings
- Evaluates performance and generates classification reports

**Model Registration (`register.py`)**
- Connects to Azure ML workspace
- Registers MLFlow model in Azure ML
- Creates versioned model entries
- Saves registration metadata for deployment

**Deployment Scripts**
- `deploy_managed_endpoint.py`: Primary Azure ML managed endpoint with archival
- `deploy_aci.py`: ACI-style deployment for cost optimization
- `deploy_azure_ml.py`: Azure ML integration verification

### Utility Modules (`src/utilities/`)

**Preprocessing (`preprocessing.py`)**
- Centralized `PurchaseDataPreprocessor` class
- Consistent transformations across training/testing/inference
- MLFlow-compatible data types
- Configurable missing data handling

**Local Development (`local_inference.py`)**
- Flask-based local inference server
- REST API endpoints for development testing
- Health checks and model information endpoints
- Sample data testing capabilities

**Server Management (`server_manager.py`)**
- Deployment archival system
- Timestamped backup management
- Rollback and debugging support

### Configuration System (`config/`)

**Main Configuration (`config.yaml`)**
- Environment variables integration via `piny`
- Data processing settings
- Model configuration
- Deployment parameters

**Configuration Loader (`config_loader.py`)**
- Centralized configuration loading
- Environment variable substitution
- Validation and error handling

## MLOps Workflow

### 1. Data Pipeline
```
Raw Data â†’ Preprocessing â†’ Feature Engineering â†’ Validation â†’ Storage
```

### 2. Training Pipeline
```
Processed Data â†’ Model Training â†’ Evaluation â†’ MLFlow Logging â†’ Artifact Storage
```

### 3. Deployment Pipeline
```
Trained Model â†’ Registration â†’ Environment Setup â†’ Endpoint Creation â†’ Testing
```

### 4. Inference Pipeline
```
Input Data â†’ Preprocessing â†’ Model Prediction â†’ Response Formatting â†’ Output
```

## Deployment Archival System

The system includes an automated deployment archival feature:

**ğŸ“ Location**: `/server/archives/`
**ğŸ“‹ Purpose**: Operational intelligence and rollback capability

**Archived Components:**
- Deployment scripts and configurations
- Preprocessing utilities
- Model artifacts and metadata
- Deployment timestamps and version info

**Benefits:**
- Easy rollback to previous deployments
- Debugging deployment issues
- Historical deployment tracking
- Environment consistency verification

## Technology Stack Integration

**Azure ML SDK v2**
- Modern Azure ML integration
- Managed online endpoints
- Experiment tracking
- Model registry

**MLFlow**
- Model packaging and versioning
- Experiment tracking
- Model deployment format
- Schema validation

**Scikit-learn**
- Model implementation
- Preprocessing utilities
- Performance evaluation

**Configuration Management**
- `piny` for environment variable handling
- YAML-based configuration
- Secrets management

## Security Considerations

**Environment Variables**
- Sensitive data in `.env.local` (not committed)
- Runtime substitution via `piny`
- Azure credentials management

**Model Security**
- Azure ML managed authentication
- Endpoint access control
- Model artifact protection

**Development Security**
- Local development isolation
- Test data generation (no real user data)
- Configuration validation

See [CONFIGURATION.md](CONFIGURATION.md) for detailed configuration options and [DEPLOYMENT_GUIDE.md](DEPLOYMENT_GUIDE.md) for deployment strategies.